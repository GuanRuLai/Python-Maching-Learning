{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMIiRd6ZVX8Mfu4UkW0MG/3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GuanRuLai/Python-Maching-Learning/blob/main/Linear_Discriminant_Analysis(LDA).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data preprocessing"
      ],
      "metadata": {
        "id": "rw0S4d48OgI7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import dataset"
      ],
      "metadata": {
        "id": "TOTSfuhdOkDS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "EKENt3OvGtWZ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "if not os.path.isdir(\"HappyML\"):\n",
        "  os.system(\"git clone https://github.com/cnchi/HappyML.git\")\n",
        "\n",
        "import pandas as pd\n",
        "df = pd.read_csv(\"Wine.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split independent variables and dependent variable"
      ],
      "metadata": {
        "id": "oIkL2C_0OqZ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import HappyML.preprocessor as pp\n",
        "\n",
        "X, Y = pp.decomposition(dataset=df, x_columns=[i for i in range(13)], y_columns=[-1])\n",
        "X = X.values\n",
        "Y = Y.values\n",
        "print(X)\n",
        "print(Y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zoh9NUbsOrQG",
        "outputId": "e9841033-635b-4220-fbe7-f4c5029db537"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1.423e+01 1.710e+00 2.430e+00 ... 1.040e+00 3.920e+00 1.065e+03]\n",
            " [1.320e+01 1.780e+00 2.140e+00 ... 1.050e+00 3.400e+00 1.050e+03]\n",
            " [1.316e+01 2.360e+00 2.670e+00 ... 1.030e+00 3.170e+00 1.185e+03]\n",
            " ...\n",
            " [1.327e+01 4.280e+00 2.260e+00 ... 5.900e-01 1.560e+00 8.350e+02]\n",
            " [1.317e+01 2.590e+00 2.370e+00 ... 6.000e-01 1.620e+00 8.400e+02]\n",
            " [1.413e+01 4.100e+00 2.740e+00 ... 6.100e-01 1.600e+00 5.600e+02]]\n",
            "[[1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [3]\n",
            " [3]\n",
            " [3]\n",
            " [3]\n",
            " [3]\n",
            " [3]\n",
            " [3]\n",
            " [3]\n",
            " [3]\n",
            " [3]\n",
            " [3]\n",
            " [3]\n",
            " [3]\n",
            " [3]\n",
            " [3]\n",
            " [3]\n",
            " [3]\n",
            " [3]\n",
            " [3]\n",
            " [3]\n",
            " [3]\n",
            " [3]\n",
            " [3]\n",
            " [3]\n",
            " [3]\n",
            " [3]\n",
            " [3]\n",
            " [3]\n",
            " [3]\n",
            " [3]\n",
            " [3]\n",
            " [3]\n",
            " [3]\n",
            " [3]\n",
            " [3]\n",
            " [3]\n",
            " [3]\n",
            " [3]\n",
            " [3]\n",
            " [3]\n",
            " [3]\n",
            " [3]\n",
            " [3]\n",
            " [3]\n",
            " [3]\n",
            " [3]\n",
            " [3]\n",
            " [3]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Handle missing data"
      ],
      "metadata": {
        "id": "PIpg7HvIOvVg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IVeAJFyGOvEC",
        "outputId": "488bcc07-59d6-43a1-8b8b-ab81408c97e0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Alcohol                 0\n",
            "Malic_Acid              0\n",
            "Ash                     0\n",
            "Ash_Alcanity            0\n",
            "Magnesium               0\n",
            "Total_Phenols           0\n",
            "Flavanoids              0\n",
            "Nonflavanoid_Phenols    0\n",
            "Proanthocyanins         0\n",
            "Color_Intensity         0\n",
            "Hue                     0\n",
            "OD280                   0\n",
            "Proline                 0\n",
            "Customer_Segment        0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split training set and testing set"
      ],
      "metadata": {
        "id": "pN_yAi2TO1Nu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=0)\n",
        "print(X_train)\n",
        "print(X_test)\n",
        "print(Y_train)\n",
        "print(Y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YjZHdbNWO3Gd",
        "outputId": "795f8001-0e66-46d7-92c7-c1e98659026c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1.369e+01 3.260e+00 2.540e+00 ... 9.600e-01 1.820e+00 6.800e+02]\n",
            " [1.269e+01 1.530e+00 2.260e+00 ... 9.600e-01 2.060e+00 4.950e+02]\n",
            " [1.162e+01 1.990e+00 2.280e+00 ... 1.160e+00 2.960e+00 3.450e+02]\n",
            " ...\n",
            " [1.242e+01 1.610e+00 2.190e+00 ... 1.060e+00 2.960e+00 3.450e+02]\n",
            " [1.390e+01 1.680e+00 2.120e+00 ... 9.100e-01 3.330e+00 9.850e+02]\n",
            " [1.416e+01 2.510e+00 2.480e+00 ... 6.200e-01 1.710e+00 6.600e+02]]\n",
            "[[1.374e+01 1.670e+00 2.250e+00 1.640e+01 1.180e+02 2.600e+00 2.900e+00\n",
            "  2.100e-01 1.620e+00 5.850e+00 9.200e-01 3.200e+00 1.060e+03]\n",
            " [1.279e+01 2.670e+00 2.480e+00 2.200e+01 1.120e+02 1.480e+00 1.360e+00\n",
            "  2.400e-01 1.260e+00 1.080e+01 4.800e-01 1.470e+00 4.800e+02]\n",
            " [1.237e+01 1.130e+00 2.160e+00 1.900e+01 8.700e+01 3.500e+00 3.100e+00\n",
            "  1.900e-01 1.870e+00 4.450e+00 1.220e+00 2.870e+00 4.200e+02]\n",
            " [1.356e+01 1.730e+00 2.460e+00 2.050e+01 1.160e+02 2.960e+00 2.780e+00\n",
            "  2.000e-01 2.450e+00 6.250e+00 9.800e-01 3.030e+00 1.120e+03]\n",
            " [1.305e+01 5.800e+00 2.130e+00 2.150e+01 8.600e+01 2.620e+00 2.650e+00\n",
            "  3.000e-01 2.010e+00 2.600e+00 7.300e-01 3.100e+00 3.800e+02]\n",
            " [1.156e+01 2.050e+00 3.230e+00 2.850e+01 1.190e+02 3.180e+00 5.080e+00\n",
            "  4.700e-01 1.870e+00 6.000e+00 9.300e-01 3.690e+00 4.650e+02]\n",
            " [1.406e+01 2.150e+00 2.610e+00 1.760e+01 1.210e+02 2.600e+00 2.510e+00\n",
            "  3.100e-01 1.250e+00 5.050e+00 1.060e+00 3.580e+00 1.295e+03]\n",
            " [1.236e+01 3.830e+00 2.380e+00 2.100e+01 8.800e+01 2.300e+00 9.200e-01\n",
            "  5.000e-01 1.040e+00 7.650e+00 5.600e-01 1.580e+00 5.200e+02]\n",
            " [1.225e+01 1.730e+00 2.120e+00 1.900e+01 8.000e+01 1.650e+00 2.030e+00\n",
            "  3.700e-01 1.630e+00 3.400e+00 1.000e+00 3.170e+00 5.100e+02]\n",
            " [1.208e+01 1.830e+00 2.320e+00 1.850e+01 8.100e+01 1.600e+00 1.500e+00\n",
            "  5.200e-01 1.640e+00 2.400e+00 1.080e+00 2.270e+00 4.800e+02]\n",
            " [1.336e+01 2.560e+00 2.350e+00 2.000e+01 8.900e+01 1.400e+00 5.000e-01\n",
            "  3.700e-01 6.400e-01 5.600e+00 7.000e-01 2.470e+00 7.800e+02]\n",
            " [1.388e+01 5.040e+00 2.230e+00 2.000e+01 8.000e+01 9.800e-01 3.400e-01\n",
            "  4.000e-01 6.800e-01 4.900e+00 5.800e-01 1.330e+00 4.150e+02]\n",
            " [1.420e+01 1.760e+00 2.450e+00 1.520e+01 1.120e+02 3.270e+00 3.390e+00\n",
            "  3.400e-01 1.970e+00 6.750e+00 1.050e+00 2.850e+00 1.450e+03]\n",
            " [1.237e+01 1.070e+00 2.100e+00 1.850e+01 8.800e+01 3.520e+00 3.750e+00\n",
            "  2.400e-01 1.950e+00 4.500e+00 1.040e+00 2.770e+00 6.600e+02]\n",
            " [1.358e+01 2.580e+00 2.690e+00 2.450e+01 1.050e+02 1.550e+00 8.400e-01\n",
            "  3.900e-01 1.540e+00 8.660e+00 7.400e-01 1.800e+00 7.500e+02]\n",
            " [1.200e+01 9.200e-01 2.000e+00 1.900e+01 8.600e+01 2.420e+00 2.260e+00\n",
            "  3.000e-01 1.430e+00 2.500e+00 1.380e+00 3.120e+00 2.780e+02]\n",
            " [1.376e+01 1.530e+00 2.700e+00 1.950e+01 1.320e+02 2.950e+00 2.740e+00\n",
            "  5.000e-01 1.350e+00 5.400e+00 1.250e+00 3.000e+00 1.235e+03]\n",
            " [1.419e+01 1.590e+00 2.480e+00 1.650e+01 1.080e+02 3.300e+00 3.930e+00\n",
            "  3.200e-01 1.860e+00 8.700e+00 1.230e+00 2.820e+00 1.680e+03]\n",
            " [1.264e+01 1.360e+00 2.020e+00 1.680e+01 1.000e+02 2.020e+00 1.410e+00\n",
            "  5.300e-01 6.200e-01 5.750e+00 9.800e-01 1.590e+00 4.500e+02]\n",
            " [1.383e+01 1.650e+00 2.600e+00 1.720e+01 9.400e+01 2.450e+00 2.990e+00\n",
            "  2.200e-01 2.290e+00 5.600e+00 1.240e+00 3.370e+00 1.265e+03]\n",
            " [1.311e+01 1.010e+00 1.700e+00 1.500e+01 7.800e+01 2.980e+00 3.180e+00\n",
            "  2.600e-01 2.280e+00 5.300e+00 1.120e+00 3.180e+00 5.020e+02]\n",
            " [1.305e+01 1.650e+00 2.550e+00 1.800e+01 9.800e+01 2.450e+00 2.430e+00\n",
            "  2.900e-01 1.440e+00 4.250e+00 1.120e+00 2.510e+00 1.105e+03]\n",
            " [1.324e+01 2.590e+00 2.870e+00 2.100e+01 1.180e+02 2.800e+00 2.690e+00\n",
            "  3.900e-01 1.820e+00 4.320e+00 1.040e+00 2.930e+00 7.350e+02]\n",
            " [1.251e+01 1.730e+00 1.980e+00 2.050e+01 8.500e+01 2.200e+00 1.920e+00\n",
            "  3.200e-01 1.480e+00 2.940e+00 1.040e+00 3.570e+00 6.720e+02]\n",
            " [1.233e+01 1.100e+00 2.280e+00 1.600e+01 1.010e+02 2.050e+00 1.090e+00\n",
            "  6.300e-01 4.100e-01 3.270e+00 1.250e+00 1.670e+00 6.800e+02]\n",
            " [1.252e+01 2.430e+00 2.170e+00 2.100e+01 8.800e+01 2.550e+00 2.270e+00\n",
            "  2.600e-01 1.220e+00 2.000e+00 9.000e-01 2.780e+00 3.250e+02]\n",
            " [1.243e+01 1.530e+00 2.290e+00 2.150e+01 8.600e+01 2.740e+00 3.150e+00\n",
            "  3.900e-01 1.770e+00 3.940e+00 6.900e-01 2.840e+00 3.520e+02]\n",
            " [1.216e+01 1.610e+00 2.310e+00 2.280e+01 9.000e+01 1.780e+00 1.690e+00\n",
            "  4.300e-01 1.560e+00 2.450e+00 1.330e+00 2.260e+00 4.950e+02]\n",
            " [1.176e+01 2.680e+00 2.920e+00 2.000e+01 1.030e+02 1.750e+00 2.030e+00\n",
            "  6.000e-01 1.050e+00 3.800e+00 1.230e+00 2.500e+00 6.070e+02]\n",
            " [1.378e+01 2.760e+00 2.300e+00 2.200e+01 9.000e+01 1.350e+00 6.800e-01\n",
            "  4.100e-01 1.030e+00 9.580e+00 7.000e-01 1.680e+00 6.150e+02]\n",
            " [1.339e+01 1.770e+00 2.620e+00 1.610e+01 9.300e+01 2.850e+00 2.940e+00\n",
            "  3.400e-01 1.450e+00 4.800e+00 9.200e-01 3.220e+00 1.195e+03]\n",
            " [1.422e+01 1.700e+00 2.300e+00 1.630e+01 1.180e+02 3.200e+00 3.000e+00\n",
            "  2.600e-01 2.030e+00 6.380e+00 9.400e-01 3.310e+00 9.700e+02]\n",
            " [1.204e+01 4.300e+00 2.380e+00 2.200e+01 8.000e+01 2.100e+00 1.750e+00\n",
            "  4.200e-01 1.350e+00 2.600e+00 7.900e-01 2.570e+00 5.800e+02]\n",
            " [1.421e+01 4.040e+00 2.440e+00 1.890e+01 1.110e+02 2.850e+00 2.650e+00\n",
            "  3.000e-01 1.250e+00 5.240e+00 8.700e-01 3.330e+00 1.080e+03]\n",
            " [1.483e+01 1.640e+00 2.170e+00 1.400e+01 9.700e+01 2.800e+00 2.980e+00\n",
            "  2.900e-01 1.980e+00 5.200e+00 1.080e+00 2.850e+00 1.045e+03]\n",
            " [1.305e+01 1.770e+00 2.100e+00 1.700e+01 1.070e+02 3.000e+00 3.000e+00\n",
            "  2.800e-01 2.030e+00 5.040e+00 8.800e-01 3.350e+00 8.850e+02]]\n",
            "[[3]\n",
            " [2]\n",
            " [2]\n",
            " [3]\n",
            " [1]\n",
            " [1]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [1]\n",
            " [3]\n",
            " [2]\n",
            " [3]\n",
            " [1]\n",
            " [3]\n",
            " [3]\n",
            " [1]\n",
            " [3]\n",
            " [1]\n",
            " [2]\n",
            " [3]\n",
            " [3]\n",
            " [2]\n",
            " [3]\n",
            " [3]\n",
            " [1]\n",
            " [2]\n",
            " [3]\n",
            " [2]\n",
            " [2]\n",
            " [3]\n",
            " [2]\n",
            " [1]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [1]\n",
            " [1]\n",
            " [2]\n",
            " [2]\n",
            " [3]\n",
            " [3]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [3]\n",
            " [3]\n",
            " [1]\n",
            " [3]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [1]\n",
            " [1]\n",
            " [2]\n",
            " [1]\n",
            " [3]\n",
            " [1]\n",
            " [3]\n",
            " [1]\n",
            " [1]\n",
            " [2]\n",
            " [1]\n",
            " [2]\n",
            " [2]\n",
            " [1]\n",
            " [3]\n",
            " [2]\n",
            " [1]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [3]\n",
            " [1]\n",
            " [3]\n",
            " [3]\n",
            " [1]\n",
            " [1]\n",
            " [2]\n",
            " [3]\n",
            " [1]\n",
            " [1]\n",
            " [2]\n",
            " [2]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [3]\n",
            " [2]\n",
            " [1]\n",
            " [2]\n",
            " [3]\n",
            " [1]\n",
            " [2]\n",
            " [3]\n",
            " [3]\n",
            " [1]\n",
            " [1]\n",
            " [3]\n",
            " [1]\n",
            " [3]\n",
            " [2]\n",
            " [1]\n",
            " [1]\n",
            " [2]\n",
            " [1]\n",
            " [3]\n",
            " [2]\n",
            " [3]\n",
            " [1]\n",
            " [3]\n",
            " [3]\n",
            " [3]\n",
            " [1]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [3]\n",
            " [3]\n",
            " [2]\n",
            " [2]\n",
            " [1]\n",
            " [2]\n",
            " [3]\n",
            " [3]\n",
            " [1]\n",
            " [1]\n",
            " [3]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [1]\n",
            " [3]]\n",
            "[[1]\n",
            " [3]\n",
            " [2]\n",
            " [1]\n",
            " [2]\n",
            " [2]\n",
            " [1]\n",
            " [3]\n",
            " [2]\n",
            " [2]\n",
            " [3]\n",
            " [3]\n",
            " [1]\n",
            " [2]\n",
            " [3]\n",
            " [2]\n",
            " [1]\n",
            " [1]\n",
            " [2]\n",
            " [1]\n",
            " [2]\n",
            " [1]\n",
            " [1]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [3]\n",
            " [1]\n",
            " [1]\n",
            " [2]\n",
            " [1]\n",
            " [1]\n",
            " [1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature scaling"
      ],
      "metadata": {
        "id": "dEx9LAooPAYj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "sc_X = StandardScaler()\n",
        "X_train = sc_X.fit_transform(X_train)\n",
        "X_test = sc_X.transform(X_test)\n",
        "print(X_train)\n",
        "print(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l6cY3fUwPAsJ",
        "outputId": "596e59cb-eced-48af-86fe-7c036cefd916"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0.87668336  0.79842885  0.64412971 ...  0.0290166  -1.06412236\n",
            "  -0.2059076 ]\n",
            " [-0.36659076 -0.7581304  -0.39779858 ...  0.0290166  -0.73083231\n",
            "  -0.81704676]\n",
            " [-1.69689407 -0.34424759 -0.32337513 ...  0.90197362  0.51900537\n",
            "  -1.31256499]\n",
            " ...\n",
            " [-0.70227477 -0.68615078 -0.65828065 ...  0.46549511  0.51900537\n",
            "  -1.31256499]\n",
            " [ 1.13777093 -0.62316862 -0.91876272 ... -0.18922266  1.03282752\n",
            "   0.80164614]\n",
            " [ 1.4610222   0.12361993  0.42085937 ... -1.45501034 -1.2168803\n",
            "  -0.2719767 ]]\n",
            "[[ 9.38847070e-01 -6.32166068e-01 -4.35010303e-01 -9.19695615e-01\n",
            "   1.26324041e+00  5.59998633e-01  9.77754158e-01 -1.20637533e+00\n",
            "   2.36680192e-02  3.39284695e-01 -1.45574805e-01  8.52295413e-01\n",
            "   1.04940526e+00]\n",
            " [-2.42263344e-01  2.67579163e-01  4.20859365e-01  7.12764102e-01\n",
            "   8.40672358e-01 -1.27747161e+00 -6.05828120e-01 -9.70634096e-01\n",
            "  -5.87397203e-01  2.42611713e+00 -2.06608025e+00 -1.55017035e+00\n",
            "  -8.66598582e-01]\n",
            " [-7.64438475e-01 -1.11802849e+00 -7.69915825e-01 -1.61767889e-01\n",
            "  -9.20027861e-01  2.03653722e+00  1.18341419e+00 -1.36353615e+00\n",
            "   4.48018868e-01 -2.50930538e-01  1.16386073e+00  3.94021597e-01\n",
            "  -1.06480588e+00]\n",
            " [ 7.15057728e-01 -5.78181354e-01  3.46435916e-01  2.75498106e-01\n",
            "   1.12238439e+00  1.15061407e+00  8.54358136e-01 -1.28495574e+00\n",
            "   1.43251284e+00  5.07917619e-01  1.16312302e-01  6.16214963e-01\n",
            "   1.24761256e+00]\n",
            " [ 8.09879269e-02  3.08378173e+00 -8.81550999e-01  5.67008770e-01\n",
            "  -9.90455870e-01  5.92810602e-01  7.20679112e-01 -4.99151627e-01\n",
            "   6.85655343e-01 -1.03085781e+00 -9.74883977e-01  7.13424560e-01\n",
            "  -1.19694407e+00]\n",
            " [-1.77149051e+00 -2.90262880e-01  3.21173872e+00  2.60758342e+00\n",
            "   1.33366842e+00  1.51154572e+00  3.21944855e+00  8.36715367e-01\n",
            "   4.48018868e-01  4.02522042e-01 -1.01926954e-01  1.53276259e+00\n",
            "  -9.16150406e-01]\n",
            " [ 1.33669479e+00 -2.00288357e-01  9.04611787e-01 -5.69882819e-01\n",
            "   1.47452444e+00  5.59998633e-01  5.76717087e-01 -4.20571216e-01\n",
            "  -6.04371237e-01  2.01884783e-03  4.65495111e-01  1.38000466e+00\n",
            "   1.82571717e+00]\n",
            " [-7.76871216e-01  1.31128363e+00  4.87421183e-02  4.21253438e-01\n",
            "  -8.49599852e-01  6.78191041e-02 -1.05828020e+00  1.07245660e+00\n",
            "  -9.60825950e-01  1.09813285e+00 -1.71689745e+00 -1.39741241e+00\n",
            "  -7.34460386e-01]\n",
            " [-9.13631369e-01 -5.78181354e-01 -9.18762724e-01 -1.61767889e-01\n",
            "  -1.41302392e+00 -9.98569875e-01  8.31330005e-02  5.09112525e-02\n",
            "   4.06420531e-02 -6.93591962e-01  2.03608004e-01  8.10634157e-01\n",
            "  -7.67494935e-01]\n",
            " [-1.12498797e+00 -4.88206831e-01 -1.74528230e-01 -3.07523221e-01\n",
            "  -1.34259591e+00 -1.08059980e+00 -4.61866095e-01  1.22961742e+00\n",
            "   5.76160871e-02 -1.11517427e+00  5.52790813e-01 -4.39203523e-01\n",
            "  -8.66598582e-01]\n",
            " [ 4.66402904e-01  1.68607187e-01 -6.28930558e-02  1.29742774e-01\n",
            "  -7.79171843e-01 -1.40871948e+00 -1.49016628e+00  5.09112525e-02\n",
            "  -1.63978731e+00  2.33889118e-01 -1.10582753e+00 -1.61461816e-01\n",
            "   1.24437889e-01]\n",
            " [ 1.11290545e+00  2.39997536e+00 -5.09433752e-01  1.29742774e-01\n",
            "  -1.41302392e+00 -2.09777082e+00 -1.65469430e+00  2.86652487e-01\n",
            "  -1.57189117e+00 -6.12184986e-02 -1.62960174e+00 -1.74458954e+00\n",
            "  -1.08132315e+00]\n",
            " [ 1.51075317e+00 -5.51188997e-01  3.09224191e-01 -1.26950841e+00\n",
            "   8.40672358e-01  1.65919958e+00  1.48162125e+00 -1.84829982e-01\n",
            "   6.17759208e-01  7.18708773e-01  4.21847260e-01  3.66247427e-01\n",
            "   2.33775268e+00]\n",
            " [-7.64438475e-01 -1.17201321e+00 -9.93186174e-01 -3.07523221e-01\n",
            "  -8.49599852e-01  2.06934919e+00  1.85180931e+00 -9.70634096e-01\n",
            "   5.83811140e-01 -2.29851422e-01  3.78199409e-01  2.55150744e-01\n",
            "  -2.71976699e-01]\n",
            " [ 7.39923211e-01  1.86602092e-01  1.20230558e+00  1.44154076e+00\n",
            "   3.47676297e-01 -1.16262972e+00 -1.14054421e+00  2.08072075e-01\n",
            "  -1.12124252e-01  1.52393098e+00 -9.31236125e-01 -1.09189653e+00\n",
            "   2.53342422e-02]\n",
            " [-1.22444990e+00 -1.30697499e+00 -1.36530342e+00 -1.61767889e-01\n",
            "  -9.90455870e-01  2.64690916e-01  3.19642042e-01 -4.99151627e-01\n",
            "  -2.98838626e-01 -1.07301604e+00  1.86222635e+00  7.41198731e-01\n",
            "  -1.53389647e+00]\n",
            " [ 9.63712552e-01 -7.58130400e-01  1.23951731e+00 -1.60125576e-02\n",
            "   2.24923253e+00  1.13420808e+00  8.13226129e-01  1.07245660e+00\n",
            "  -4.34630898e-01  1.49572656e-01  1.29480428e+00  5.74553707e-01\n",
            "   1.62750987e+00]\n",
            " [ 1.49832042e+00 -7.04145686e-01  4.20859365e-01 -8.90544549e-01\n",
            "   5.58960323e-01  1.70841753e+00  2.03690334e+00 -3.41990805e-01\n",
            "   4.31044834e-01  1.54079428e+00  1.20750858e+00  3.24586171e-01\n",
            "   3.09754730e+00]\n",
            " [-4.28754462e-01 -9.11087089e-01 -1.29087997e+00 -8.03091350e-01\n",
            "  -4.46374703e-03 -3.91548456e-01 -5.54413111e-01  1.30819784e+00\n",
            "  -1.67373538e+00  2.97126464e-01  1.16312302e-01 -1.38352533e+00\n",
            "  -9.65702229e-01]\n",
            " [ 1.05074174e+00 -6.50160973e-01  8.67400062e-01 -6.86487084e-01\n",
            "  -4.27031800e-01  3.13908869e-01  1.07030117e+00 -1.12779492e+00\n",
            "   1.16092829e+00  2.33889118e-01  1.25115643e+00  1.08837586e+00\n",
            "   1.72661352e+00]\n",
            " [ 1.55584374e-01 -1.22599792e+00 -2.48165516e+00 -1.32781054e+00\n",
            "  -1.55387994e+00  1.18342604e+00  1.26567821e+00 -8.13473273e-01\n",
            "   1.14395426e+00  1.07414425e-01  7.27382218e-01  8.24521243e-01\n",
            "  -7.93922574e-01]\n",
            " [ 8.09879269e-02 -6.50160973e-01  6.81341438e-01 -4.53278553e-01\n",
            "  -1.45319765e-01  3.13908869e-01  4.94453073e-01 -5.77732039e-01\n",
            "  -2.81864592e-01 -3.35247000e-01  7.27382218e-01 -1.05913475e-01\n",
            "   1.19806073e+00]\n",
            " [ 3.17210010e-01  1.95599544e-01  1.87211663e+00  4.21253438e-01\n",
            "   1.26324041e+00  8.88118319e-01  7.61811120e-01  2.08072075e-01\n",
            "   3.63148698e-01 -3.05736238e-01  3.78199409e-01  4.77344109e-01\n",
            "  -2.42175814e-02]\n",
            " [-5.90380098e-01 -5.78181354e-01 -1.43972687e+00  2.75498106e-01\n",
            "  -1.06088388e+00 -9.62407389e-02 -2.99800193e-02 -3.41990805e-01\n",
            "  -2.13968456e-01 -8.87519825e-01  3.78199409e-01  1.36611757e+00\n",
            "  -2.32335240e-01]\n",
            " [-8.14169440e-01 -1.14502085e+00 -3.23375129e-01 -1.03629988e+00\n",
            "   6.59642617e-02 -3.42330503e-01 -8.83469169e-01  2.09400195e+00\n",
            "  -2.03019009e+00 -7.48397663e-01  1.29480428e+00 -1.27242864e+00\n",
            "  -2.05907601e-01]\n",
            " [-5.77947357e-01  5.16403072e-02 -7.32704101e-01  4.21253438e-01\n",
            "  -8.49599852e-01  4.77968712e-01  3.29925044e-01 -8.13473273e-01\n",
            "  -6.55293339e-01 -1.28380720e+00 -2.32870507e-01  2.69037829e-01\n",
            "  -1.37863409e+00]\n",
            " [-6.89842028e-01 -7.58130400e-01 -2.86163404e-01  5.67008770e-01\n",
            "  -9.90455870e-01  7.89682413e-01  1.23482920e+00  2.08072075e-01\n",
            "   2.78278529e-01 -4.65937515e-01 -1.14947538e+00  3.52360341e-01\n",
            "  -1.28944081e+00]\n",
            " [-1.02552604e+00 -6.86150782e-01 -2.11739955e-01  9.45972633e-01\n",
            "  -7.08743835e-01 -7.85292079e-01 -2.66489061e-01  5.22393721e-01\n",
            "  -7.81761846e-02 -1.09409516e+00  1.64398709e+00 -4.53090608e-01\n",
            "  -8.17046759e-01]\n",
            " [-1.52283569e+00  2.76576615e-01  2.05817525e+00  1.29742774e-01\n",
            "   2.06820279e-01 -8.34510032e-01  8.31330005e-02  1.85826072e+00\n",
            "  -9.43851916e-01 -5.24959039e-01  1.20750858e+00 -1.19800560e-01\n",
            "  -4.47059809e-01]\n",
            " [ 9.88578035e-01  3.48556233e-01 -2.48951679e-01  7.12764102e-01\n",
            "  -7.08743835e-01 -1.49074940e+00 -1.30507224e+00  3.65232898e-01\n",
            "  -9.77799984e-01  1.91178671e+00 -1.10582753e+00 -1.25854156e+00\n",
            "  -4.20632170e-01]\n",
            " [ 5.03701128e-01 -5.42191545e-01  9.41823511e-01 -1.00714881e+00\n",
            "  -4.97459808e-01  9.70148241e-01  1.01888616e+00 -1.84829982e-01\n",
            "  -2.64890558e-01 -1.03376729e-01 -1.45574805e-01  8.80069584e-01\n",
            "   1.49537167e+00]\n",
            " [ 1.53561865e+00 -6.05173711e-01 -2.48951679e-01 -9.48846682e-01\n",
            "   1.26324041e+00  1.54435769e+00  1.08058418e+00 -8.13473273e-01\n",
            "   7.19603411e-01  5.62723319e-01 -5.82791026e-02  1.00505335e+00\n",
            "   7.52094321e-01]\n",
            " [-1.17471893e+00  1.73416389e+00  4.87421183e-02  7.12764102e-01\n",
            "  -1.41302392e+00 -2.60300582e-01 -2.04791050e-01  4.43813310e-01\n",
            "  -4.34630898e-01 -1.03085781e+00 -7.12996870e-01 -2.25909628e-02\n",
            "  -5.36253092e-01]\n",
            " [ 1.52318591e+00  1.50023013e+00  2.72012467e-01 -1.90918956e-01\n",
            "   7.70244349e-01  9.70148241e-01  7.20679112e-01 -4.99151627e-01\n",
            "  -6.04371237e-01  8.21194866e-02 -3.63814061e-01  1.03282752e+00\n",
            "   1.11547436e+00]\n",
            " [ 2.29401586e+00 -6.59158425e-01 -7.32704101e-01 -1.61932121e+00\n",
            "  -2.15747773e-01  8.88118319e-01  1.06001817e+00 -5.77732039e-01\n",
            "   6.34733242e-01  6.52561942e-02  5.52790813e-01  3.66247427e-01\n",
            "   9.99853439e-01]\n",
            " [ 8.09879269e-02 -5.42191545e-01 -9.93186174e-01 -7.44789217e-01\n",
            "   4.88532314e-01  1.21623801e+00  1.08058418e+00 -6.56312450e-01\n",
            "   7.19603411e-01 -2.19697526e-03 -3.20166209e-01  1.06060169e+00\n",
            "   4.71300654e-01]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Applying LDA to reduce the dimension"
      ],
      "metadata": {
        "id": "FvEO79i0x479"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
        "\n",
        "lda = LDA(n_components=2)\n",
        "X_train = lda.fit_transform(X_train, Y_train)\n",
        "X_test = lda.transform(X_test)\n",
        "print(X_train)\n",
        "print(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NebAuPKtx7lb",
        "outputId": "dc04820b-559f-4310-8eb2-5a7882290139"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 3.57315552  1.94018924]\n",
            " [ 0.85475898 -2.08182977]\n",
            " [ 0.62173655 -3.06234453]\n",
            " [ 4.80786412  2.00638739]\n",
            " [-3.8579759   0.14987256]\n",
            " [-3.59455458  1.24961706]\n",
            " [-0.53772906 -3.0852704 ]\n",
            " [ 0.04058577 -2.47312446]\n",
            " [ 0.99835348 -3.36989668]\n",
            " [-3.74095658  1.94844242]\n",
            " [ 3.76035226  0.82126218]\n",
            " [-0.15106412 -1.86820292]\n",
            " [ 3.62762899  2.05460026]\n",
            " [-3.94229781  2.80328429]\n",
            " [ 3.33429017  0.73627798]\n",
            " [ 3.90206871  1.03276135]\n",
            " [-3.55835472  0.18783108]\n",
            " [ 5.63175281  2.40524214]\n",
            " [-5.56217254  0.85694946]\n",
            " [ 0.23296188 -3.94615581]\n",
            " [ 5.03141997  3.23313754]\n",
            " [ 3.52861651  0.94605778]\n",
            " [-1.17815662 -2.17294825]\n",
            " [ 3.58320131  0.67947364]\n",
            " [ 5.21649905  2.41090952]\n",
            " [-3.01647841  1.24411621]\n",
            " [ 1.86178658 -0.47484926]\n",
            " [ 3.93816398 -0.2204059 ]\n",
            " [-1.0836235  -3.32496762]\n",
            " [ 1.8691488  -0.63362283]\n",
            " [ 3.27717205  1.51263542]\n",
            " [-0.47842302 -1.16766723]\n",
            " [-4.14433134  1.37391708]\n",
            " [ 2.45009727 -2.49336285]\n",
            " [-1.20844631 -2.30679956]\n",
            " [ 2.55631466 -0.98550214]\n",
            " [-1.6091476   0.55066705]\n",
            " [-5.52462148  2.19178828]\n",
            " [-2.44685583 -2.28937848]\n",
            " [-1.95474568 -2.02963924]\n",
            " [ 5.54394234  1.5236766 ]\n",
            " [ 5.74409562  1.85156779]\n",
            " [ 1.13553056 -3.93865462]\n",
            " [-1.2483554  -3.08106324]\n",
            " [-0.00961488 -3.62708415]\n",
            " [ 5.21418108  2.66981962]\n",
            " [ 4.2290474   0.3886969 ]\n",
            " [-3.94237521  0.76214343]\n",
            " [ 5.30822458  2.18894363]\n",
            " [-0.20862902 -3.05785486]\n",
            " [ 0.47295413 -2.560251  ]\n",
            " [ 0.46692465 -1.86886738]\n",
            " [-1.05818513 -2.61576658]\n",
            " [ 0.33551985 -3.26643922]\n",
            " [-4.74777848  2.23081211]\n",
            " [-2.80968166  1.32816126]\n",
            " [-1.02804047 -2.60107642]\n",
            " [-6.15432728  2.12945198]\n",
            " [ 4.33944259  1.23494233]\n",
            " [-3.63172128  0.54074799]\n",
            " [ 4.79575236  1.25996976]\n",
            " [-4.13914056  0.36020476]\n",
            " [-3.94468876  3.0153646 ]\n",
            " [-0.42472714 -2.30200526]\n",
            " [-5.17777666  2.36899585]\n",
            " [-1.3044572  -2.87041347]\n",
            " [ 0.06991014 -2.78082083]\n",
            " [-4.98245326  3.83183665]\n",
            " [ 4.3064623   2.4129711 ]\n",
            " [ 0.29208614 -2.06937039]\n",
            " [-5.0934408   3.0899463 ]\n",
            " [ 0.61101399  0.17866792]\n",
            " [ 1.12081287 -2.87291369]\n",
            " [-0.77339273 -2.03777551]\n",
            " [ 2.57603424  0.08537633]\n",
            " [-4.29104423  2.28661799]\n",
            " [ 5.255722    0.61832811]\n",
            " [ 5.7318737   0.19267558]\n",
            " [-6.24884704  3.55128212]\n",
            " [-5.38587866  1.77559442]\n",
            " [ 1.31025756 -2.52845345]\n",
            " [ 5.00526015  2.31115606]\n",
            " [-4.31499585  1.99154644]\n",
            " [-3.92894005  2.13127776]\n",
            " [-0.05838671 -2.60549973]\n",
            " [-0.42566332 -1.68426706]\n",
            " [-3.5253992   0.16028802]\n",
            " [-4.42913323  2.47869828]\n",
            " [-2.85063973  1.1163819 ]\n",
            " [ 4.46460374  3.55045935]\n",
            " [-1.21751159 -1.31441447]\n",
            " [-4.94290391  1.29321013]\n",
            " [-1.70880192 -2.10638157]\n",
            " [ 3.42314438  1.21989584]\n",
            " [-5.58393165  2.49598525]\n",
            " [-0.71859407 -2.67293812]\n",
            " [ 4.01611408  0.13560479]\n",
            " [ 4.64009352 -0.06178578]\n",
            " [-3.85066489  1.66509736]\n",
            " [-3.47123425 -0.07349273]\n",
            " [ 4.17391188  0.51767626]\n",
            " [-4.09941682  3.11353194]\n",
            " [ 4.29592104  0.18486038]\n",
            " [-0.15570245 -3.78905263]\n",
            " [-3.29789207  1.48134709]\n",
            " [-4.0655232   1.02548943]\n",
            " [-0.63468603 -2.68007872]\n",
            " [-4.4641561   2.38128912]\n",
            " [ 4.52246935  1.96313747]\n",
            " [ 0.79712615 -3.04743012]\n",
            " [ 4.91056287  1.22473167]\n",
            " [-3.77150311  0.30882908]\n",
            " [ 3.5444653   1.05962644]\n",
            " [ 4.36398757  1.78816415]\n",
            " [ 4.86008035  2.32823762]\n",
            " [-3.46481941  1.07890379]\n",
            " [-1.65664035 -3.72251678]\n",
            " [ 0.26593072 -2.87995582]\n",
            " [-0.66345544 -2.36083579]\n",
            " [-0.33965319 -5.76922451]\n",
            " [ 5.14221842  1.93740967]\n",
            " [ 5.75746454  2.94776345]\n",
            " [ 0.42253477 -1.5887479 ]\n",
            " [ 0.96267148 -1.57482982]\n",
            " [-2.5640305   0.20647539]\n",
            " [-2.30398129 -1.49865287]\n",
            " [ 4.91741587  2.32620455]\n",
            " [ 5.20879938  2.96660159]\n",
            " [-3.60895143  2.468315  ]\n",
            " [-4.58647662  2.42583146]\n",
            " [ 2.89493473  1.15627605]\n",
            " [-0.09551518 -1.90444969]\n",
            " [ 1.30043304 -0.87538895]\n",
            " [ 0.16805348 -3.21257614]\n",
            " [-3.19016989  1.66680508]\n",
            " [-2.08858151  0.83647089]\n",
            " [-4.25960623  1.54637835]\n",
            " [ 1.68647094 -3.83427605]\n",
            " [-0.9020576  -2.62989337]\n",
            " [-0.19105618 -3.66017053]\n",
            " [-4.20632725  0.8310719 ]\n",
            " [ 4.52910794  3.07839306]]\n",
            "[[-3.83960313  1.54567265]\n",
            " [ 5.24601727  1.72358501]\n",
            " [-0.66064228 -3.32231072]\n",
            " [-2.16667061  1.0147427 ]\n",
            " [-0.16079996 -1.27171643]\n",
            " [-5.31374258 -2.22014536]\n",
            " [-4.78386714  3.11508054]\n",
            " [ 5.55863966  0.88556084]\n",
            " [-1.29772139 -2.40714074]\n",
            " [ 0.53068371 -2.37759837]\n",
            " [ 2.36900593  1.81859204]\n",
            " [ 5.14502202  1.88061526]\n",
            " [-5.27947032  3.32510044]\n",
            " [-2.70452577 -2.61522323]\n",
            " [ 4.32314426  2.14569837]\n",
            " [-0.65835601 -4.67751669]\n",
            " [-4.07332713  1.95266123]\n",
            " [-6.55291385  4.01098911]\n",
            " [ 2.40020179 -1.14618328]\n",
            " [-5.14219986  2.02120623]\n",
            " [-2.46475469 -2.81225673]\n",
            " [-2.5190649   1.07965428]\n",
            " [-1.79798575  0.47987658]\n",
            " [-1.43423986 -2.41298601]\n",
            " [ 1.11433225 -0.98310413]\n",
            " [ 0.28604133 -2.81262488]\n",
            " [-1.21198193 -2.73115246]\n",
            " [ 0.84900431 -3.34996047]\n",
            " [-1.03105294 -0.53029203]\n",
            " [ 4.83489722  2.08108766]\n",
            " [-4.75464421  2.30157612]\n",
            " [-3.33786142  1.51860576]\n",
            " [ 1.02045007 -1.04261267]\n",
            " [-3.1347464   2.97819832]\n",
            " [-4.25385909  1.84683986]\n",
            " [-3.16058359 -0.39860037]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classification model processing"
      ],
      "metadata": {
        "id": "mk1kl7cMSXPs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model training"
      ],
      "metadata": {
        "id": "LLgo1M8vSbLQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "classifier = LogisticRegression(random_state=0)\n",
        "classifier.fit(X_train, Y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "id": "9zsa4guaSajh",
        "outputId": "e68dac6c-978e-4fdf-fb83-370fa7c60e41"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(random_state=0)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=0)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model prediction"
      ],
      "metadata": {
        "id": "DGPgK4vqUw7v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Y_pred = pd.DataFrame(classifier.predict(X_test), columns=[\"pred_Classification\"])\n",
        "Y_test = pd.DataFrame(Y_test, columns=[\"true_Classification\"])\n",
        "df_pred = pd.concat([Y_test, Y_pred], axis=1)\n",
        "print(df_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ff-uxQPWUzos",
        "outputId": "5806ffc3-6496-490b-8115-9e45b397f1d0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    true_Classification  pred_Classification\n",
            "0                     1                    1\n",
            "1                     3                    3\n",
            "2                     2                    2\n",
            "3                     1                    1\n",
            "4                     2                    2\n",
            "5                     2                    2\n",
            "6                     1                    1\n",
            "7                     3                    3\n",
            "8                     2                    2\n",
            "9                     2                    2\n",
            "10                    3                    3\n",
            "11                    3                    3\n",
            "12                    1                    1\n",
            "13                    2                    2\n",
            "14                    3                    3\n",
            "15                    2                    2\n",
            "16                    1                    1\n",
            "17                    1                    1\n",
            "18                    2                    2\n",
            "19                    1                    1\n",
            "20                    2                    2\n",
            "21                    1                    1\n",
            "22                    1                    1\n",
            "23                    2                    2\n",
            "24                    2                    2\n",
            "25                    2                    2\n",
            "26                    2                    2\n",
            "27                    2                    2\n",
            "28                    2                    2\n",
            "29                    3                    3\n",
            "30                    1                    1\n",
            "31                    1                    1\n",
            "32                    2                    2\n",
            "33                    1                    1\n",
            "34                    1                    1\n",
            "35                    1                    1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Make confusion matrix & Model evaluation"
      ],
      "metadata": {
        "id": "4t2W-qbRWwW2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "\n",
        "cm = confusion_matrix(Y_test, Y_pred)\n",
        "print(cm)\n",
        "print(accuracy_score(Y_test, Y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wWlXxkDpWzGn",
        "outputId": "fb24e34b-a815-44da-da4d-b1844f6080f9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[14  0  0]\n",
            " [ 0 16  0]\n",
            " [ 0  0  6]]\n",
            "1.0\n"
          ]
        }
      ]
    }
  ]
}